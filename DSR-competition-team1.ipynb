{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nominated-bermuda",
   "metadata": {},
   "source": [
    "## DSR Mini-Competition \n",
    "### Rossman Sales Prediction\n",
    "#### Team 1: John Enevoldsen, Sara Ghasemi, Mena Nasr\n",
    "\n",
    "This is a notebook to reproduce the results that are submitted for the competition. Data understanding and exploration and visualisations are not included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "false-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "centered-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, './modules/')\n",
    "import cleaning as cln\n",
    "import feature_eng as feng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-bouquet",
   "metadata": {},
   "source": [
    "## 1. Initial Data Preparation\n",
    "\n",
    "Read the files and make one data frame to be used for training and cross validation, and one to be used for the final test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "settled-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sara/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read the data from 'train', 'store' and 'holdout' files:\n",
    "\n",
    "full_df_train = pd.read_csv(\"./data/train.csv\")\n",
    "full_df_store = pd.read_csv(\"./data/store.csv\")\n",
    "full_df_holdout = pd.read_csv(\"./data/holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incredible-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the 'train' and 'store' data frames, to be used for training and cross validation:\n",
    "\n",
    "full_df_train_cv = cln.merge(full_df_train, full_df_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hairy-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the 'holdout' and 'store' data frames, to be used for final test:\n",
    "\n",
    "full_df_test = cln.merge(full_df_holdout, full_df_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-valuation",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interpreted-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Cusomers column, as was instructed to us for the competition\n",
    "\n",
    "df_train_cv = cln.drop_column(full_df_train_cv, column='Customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "biological-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target cleaning: Remove the zero and null values in targt ('Sales')\n",
    "\n",
    "df_train_cv = cln.clean_targets(df_train_cv, target='Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "armed-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows before cleaning:  531983\n",
      "Total number of rows after cleaning:  425689\n"
     ]
    }
   ],
   "source": [
    "# Feature cleaning:\n",
    "# Remove the rows with null feature values if number of null values are very small.\n",
    "# Drop the whole feature column if number of null values are not small.\n",
    "# The threshold is 10%.\n",
    "# Transform the values in 'StateHoliday' column: transform 0.0 to 0 and all column to string.\n",
    "    \n",
    "df_train_cv = cln.rough_features_cleaning(df_train_cv, threshold=0.10, drop_columns=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-repair",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Some feature engineering (namely mean encoding) are done after split of data into training and cross validation sets, to avoid data leakage, but others (make new date features, one_hot_encoding, etc.) can be done before.\n",
    "\n",
    "For the data split, the last 3 months (from 2014-05-01 to 2014-07-31) are kept for the cross validation set and the rest (from 2013-01-01 to 2014-04-30) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new date features, before split into training and cross validation sets\n",
    "\n",
    "df_train_cv = feng.dates_features(df_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "radical-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one hot encoding of StateHoliday, StoreType, Assortment before split\n",
    "\n",
    "df_train_cv = feng.one_hot_encoding(df_train_cv, 'StateHoliday')\n",
    "df_train_cv = feng.one_hot_encoding(df_train_cv, 'StoreType')\n",
    "df_train_cv = feng.one_hot_encoding(df_train_cv, 'Assortment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exotic-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and cross validation sets\n",
    "\n",
    "df_train, df_cv = feng.date_split_train_test(df_train_cv, '2014-05-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
